

EC2 CPU Utilization Anomaly Detection

Author: Sumukha C R
Project Type: Anomaly Detection using Machine Learning and Deep Learning

1. Understanding the Problem
Cloud platforms like Amazon EC2 continuously monitor various performance metrics such as CPU usage, memory consumption, and network activity. When CPU usage suddenly spikes or drops unexpectedly, it could mean something is wrong – perhaps the system is overloaded, there's a configuration error, or a failure is about to happen. Catching these unusual patterns early helps us prevent downtime and keep systems running smoothly.

For this project, I worked with the dataset ec2_cpu_utilization_24ae8d.csv from the Numenta Anomaly Benchmark (NAB). This dataset contains CPU utilization percentages recorded over time. My goal was to build an automated system that can spot unusual CPU behaviour without needing pre-labeled data telling it what's normal and what's not.

What I Aimed to Achieve : 
Analyse the data and create meaningful features from the time-series information
Train both traditional machine learning and deep learning models to detect anomalies
Compare how different models perform and understand their strengths
Summarise the findings and suggest improvements for future work

2. Why Feature Engineering Matters
Simply using raw CPU utilization numbers isn't enough to understand complex patterns like daily cycles or gradual changes. To help the models learn better, I created several additional features:

Feature Type          What It Does                                      Why It's Useful
-------------------------------------------------------------------------------------------------------------------
Rolling Mean & Std    Calculates average and variation over a window    Helps understand                     short-term trends and how volatile the data is
Z-Score               Measures how far a point is from the average      Identifies values that are unusually high or low
STL Decomposition     Breaks data into trend, seasonal, and residual    Separates long-term changes, daily patterns, and random variations
Lag Features          Previous values (1, 2, 3, 6, 12 steps back)       Lets models see what happened before
Standard Scaling      Brings all features to the same scale             Ensures no single feature dominates the others
These engineered features transform a single time series into multiple dimensions that capture both immediate changes and longer-term patterns, making the models more effective.

3. Models Used and Why
I implemented two different approaches to detect anomalies, each with its own strengths:

Isolation Forest (Traditional Machine Learning)
How it works: This algorithm randomly divides the data and finds points that stand out because they can be isolated quickly with fewer divisions.
Advantages: It's fast, easy to understand, and works well even with many features.
Settings: I used 300 decision trees and set contamination at 0.01 (expecting 1% anomalies).
Result: Produces an anomaly score for each data point.
LSTM Autoencoder (Deep Learning)
How it works: This neural network learns what "normal" patterns look like by trying to recreate them. When it struggles to recreate a sequence, that sequence is likely unusual.
Architecture: Two LSTM encoder layers compress the information ? a bottleneck captures the essence ? two LSTM decoder layers reconstruct the original sequence.
Sequence Length: Uses 24 consecutive time steps.
Result: Calculates reconstruction error – higher error means potential anomaly.
Comparing the Two Approaches
+-------------------------+---------------------------+----------------------------+
| Aspect                  | Isolation Forest          | LSTM Autoencoder           |
+-------------------------+---------------------------+----------------------------+
| Learning Type           | Traditional (point-based) | Deep Learning (sequential) |
| Training Speed          | Fast                      | Slower                     |
| Captures Daily Patterns | Partially                 | Very Well                  |
| Detects Gradual Changes | Limited                   | Yes                        |
| Easy to Interpret       | Yes                       | Moderate                   |
| Works Best For          | Sudden unusual spikes     | Long-term pattern changes  |
+-------------------------+---------------------------+----------------------------+Using both models together gives us a complete picture – Isolation Forest catches sudden outliers, while LSTM Autoencoder identifies gradual unusual patterns.

4. What I Discovered
Regular Daily Pattern: The CPU usage follows a daily cycle, which is typical for systems running scheduled tasks or batch jobs at specific times.

Anomalies Found:

Isolation Forest identified sudden spikes – instances where CPU usage jumped to 2-3 times the normal level
LSTM Autoencoder caught gradual shifts that happened during transitions between different workload levels
System Behaviour: The anomalies often occurred during transitions between low and high usage periods. This could indicate auto-scaling activities or new deployments.

Practical Benefits:

Early warnings allow teams to scale resources proactively before problems occur
Reduces downtime by enabling faster diagnosis and response
Helps maintain service level agreements (SLAs) and overall system reliability
Can be scaled to monitor multiple EC2 instances simultaneously
Overall, this project shows that intelligent, data-driven anomaly detection can be more effective than manually setting threshold alerts for different metrics.

5. Limitations and Future Scope
Current Limitation	How It Can Be Improved
Only uses CPU data	Include other metrics like memory, network traffic, and disk I/O
Fixed thresholds for anomaly detection	Implement adaptive thresholds that adjust based on recent patterns
No labeled anomaly data available	Incorporate expert feedback or use semi-supervised learning techniques
Works only in batch mode	Convert to real-time detection using AWS Lambda, S3, and CloudWatch
No production-ready interface	Build a REST API using Flask or FastAPI for easy integration with other tools
6. Conclusion
This project demonstrates a complete end-to-end anomaly detection system for monitoring cloud infrastructure metrics using both traditional machine learning and modern deep learning approaches.

The project structure is organised into clear sections (src/ for source code, notebooks/ for experiments, reports/ for documentation), and the results are presented in an easy-to-understand manner. This reflects the key skills expected from an AI/ML Engineer at the fresher level:

Data preprocessing – Cleaning and preparing data for analysis
Feature engineering – Creating meaningful inputs from raw data
Model development – Implementing and comparing different algorithms
Communication – Presenting findings through visualizations and clear explanations
Practical awareness – Understanding deployment challenges and scalability requirements
By extending this work to handle real-time data streams and multiple metrics simultaneously, this system can become a powerful tool for intelligent cloud infrastructure monitoring.